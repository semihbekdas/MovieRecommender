"""
HitRate dÃ¼ÅŸÃ¼k olmasÄ±nÄ±n nedenlerini analiz eden diagnostik script.
"""
from __future__ import annotations

from pathlib import Path
import pandas as pd
import numpy as np

BASE_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = BASE_DIR.parent
DATA_DIR = PROJECT_ROOT / "data"

import recommender_content as rc
import evaluate_content as ec


def diagnose():
    print("=" * 70)
    print("ğŸ” HIT RATE DÄ°AGNOSTÄ°K ANALÄ°ZÄ°")
    print("=" * 70)
    
    # 1. Veri yÃ¼kleme
    print("\nğŸ“‚ 1. VERÄ° YÃœKLEME")
    print("-" * 50)
    
    ratings_df = ec.load_ratings(DATA_DIR / "ratings.csv")
    links_df = ec.load_links(DATA_DIR / "links.csv")
    bundle = rc.load_artifacts()
    
    print(f"   â€¢ Ratings satÄ±r sayÄ±sÄ±: {len(ratings_df):,}")
    print(f"   â€¢ Benzersiz kullanÄ±cÄ±: {ratings_df['userId'].nunique():,}")
    print(f"   â€¢ Benzersiz movieId: {ratings_df['movieId'].nunique():,}")
    print(f"   â€¢ Links satÄ±r sayÄ±sÄ±: {len(links_df):,}")
    print(f"   â€¢ Content-Based model film sayÄ±sÄ±: {len(bundle.metadata):,}")
    
    # 2. ID eÅŸleÅŸme analizi
    print("\nğŸ”— 2. ID EÅLEÅMESÄ° ANALÄ°ZÄ°")
    print("-" * 50)
    
    movie_map = ec.build_movieid_to_tmdb(links_df)
    ratings_movie_ids = set(ratings_df['movieId'].unique())
    links_movie_ids = set(links_df['movieId'].unique())
    tmdb_ids_in_model = set(bundle.metadata['tmdb_id'].unique())
    
    # MovieLens ID'lerinden kaÃ§Ä± links'te var?
    matched_to_links = ratings_movie_ids & links_movie_ids
    print(f"   â€¢ Ratings'teki movieId sayÄ±sÄ±: {len(ratings_movie_ids):,}")
    print(f"   â€¢ Links'te eÅŸleÅŸen movieId: {len(matched_to_links):,} ({len(matched_to_links)/len(ratings_movie_ids)*100:.1f}%)")
    
    # Links'teki tmdb_id'lerden kaÃ§Ä± modelde var?
    tmdb_ids_in_links = set(links_df['tmdbId'].dropna().astype(int).unique())
    matched_to_model = tmdb_ids_in_links & tmdb_ids_in_model
    print(f"   â€¢ Links'teki tmdbId sayÄ±sÄ±: {len(tmdb_ids_in_links):,}")
    print(f"   â€¢ Content-Based modelde olan: {len(matched_to_model):,} ({len(matched_to_model)/len(tmdb_ids_in_links)*100:.1f}%)")
    
    # 3. KullanÄ±cÄ± bazlÄ± analiz
    print("\nğŸ‘¥ 3. KULLANICI BAZLI ANALÄ°Z")
    print("-" * 50)
    
    rating_threshold = 4.0
    liked_ratings = ratings_df[ratings_df['rating'] >= rating_threshold]
    
    # Her kullanÄ±cÄ±nÄ±n kaÃ§ beÄŸenisi modelde var?
    users_with_model_coverage = []
    
    for user_id in liked_ratings['userId'].unique()[:500]:  # Ä°lk 500 kullanÄ±cÄ±
        user_likes = liked_ratings[liked_ratings['userId'] == user_id]
        
        model_matched = 0
        for _, row in user_likes.iterrows():
            tmdb_id = movie_map.get(int(row['movieId']))
            if tmdb_id and tmdb_id in bundle.id_to_index:
                model_matched += 1
        
        if len(user_likes) > 0:
            coverage = model_matched / len(user_likes)
            users_with_model_coverage.append({
                'userId': user_id,
                'total_likes': len(user_likes),
                'in_model': model_matched,
                'coverage': coverage
            })
    
    coverage_df = pd.DataFrame(users_with_model_coverage)
    print(f"   â€¢ Ortalama kullanÄ±cÄ± kapsamÄ± (coverage): {coverage_df['coverage'].mean()*100:.1f}%")
    print(f"   â€¢ Medyan kullanÄ±cÄ± kapsamÄ±: {coverage_df['coverage'].median()*100:.1f}%")
    print(f"   â€¢ Min kapsamÄ±: {coverage_df['coverage'].min()*100:.1f}%")
    print(f"   â€¢ Max kapsamÄ±: {coverage_df['coverage'].max()*100:.1f}%")
    
    # KapsamÄ± dÃ¼ÅŸÃ¼k kullanÄ±cÄ±lar
    low_coverage = coverage_df[coverage_df['coverage'] < 0.3]
    print(f"   â€¢ KapsamÄ± %30'un altÄ±nda olan kullanÄ±cÄ±: {len(low_coverage)} ({len(low_coverage)/len(coverage_df)*100:.1f}%)")
    
    # 4. Content-Based benzerlik analizi
    print("\nğŸ“Š 4. CONTENT-BASED BENZERLÄ°K ANALÄ°ZÄ°")
    print("-" * 50)
    
    # Rastgele bir kullanÄ±cÄ±nÄ±n beÄŸendiÄŸi filmler arasÄ±ndaki benzerlik
    sample_user = coverage_df[coverage_df['in_model'] >= 5].iloc[0]['userId']
    user_likes = liked_ratings[liked_ratings['userId'] == sample_user]
    
    user_tmdb_ids = []
    for _, row in user_likes.iterrows():
        tmdb_id = movie_map.get(int(row['movieId']))
        if tmdb_id and tmdb_id in bundle.id_to_index:
            user_tmdb_ids.append(tmdb_id)
    
    if len(user_tmdb_ids) >= 3:
        # Film Ã§iftleri arasÄ±ndaki benzerliÄŸi hesapla
        from sklearn.metrics.pairwise import cosine_similarity
        
        similarities = []
        for i, id1 in enumerate(user_tmdb_ids[:10]):
            for id2 in user_tmdb_ids[i+1:10]:
                idx1 = bundle.id_to_index.get(id1)
                idx2 = bundle.id_to_index.get(id2)
                if idx1 is not None and idx2 is not None:
                    sim = cosine_similarity(
                        bundle.matrix[idx1], 
                        bundle.matrix[idx2]
                    )[0][0]
                    similarities.append(sim)
        
        if similarities:
            print(f"   â€¢ Ã–rnek kullanÄ±cÄ± #{sample_user} ({len(user_tmdb_ids)} film)")
            print(f"   â€¢ BeÄŸenilen filmler arasÄ± ortalama benzerlik: {np.mean(similarities):.3f}")
            print(f"   â€¢ BeÄŸenilen filmler arasÄ± max benzerlik: {np.max(similarities):.3f}")
            print(f"   â€¢ BeÄŸenilen filmler arasÄ± min benzerlik: {np.min(similarities):.3f}")
            
            if np.mean(similarities) < 0.2:
                print("   âš ï¸  DÃœÅÃœK BENZERLÄ°K: KullanÄ±cÄ±nÄ±n beÄŸendiÄŸi filmler birbirine benzemiyor!")
                print("      Bu, content-based sistemin doÄŸal sÄ±nÄ±rlamasÄ±dÄ±r.")
    
    # 5. Temel problem tespiti
    print("\nğŸ¯ 5. TEMEL PROBLEM TESPÄ°TÄ°")
    print("-" * 50)
    
    problems = []
    
    # Problem 1: DÃ¼ÅŸÃ¼k katalog Ã¶rtÃ¼ÅŸmesi
    model_coverage = len(matched_to_model) / len(tmdb_ids_in_links) * 100
    if model_coverage < 80:
        problems.append(f"âŒ Katalog Ã¶rtÃ¼ÅŸmesi dÃ¼ÅŸÃ¼k ({model_coverage:.1f}%)")
    else:
        print(f"   âœ… Katalog Ã¶rtÃ¼ÅŸmesi iyi ({model_coverage:.1f}%)")
    
    # Problem 2: DÃ¼ÅŸÃ¼k kullanÄ±cÄ± kapsamÄ±
    avg_coverage = coverage_df['coverage'].mean() * 100
    if avg_coverage < 50:
        problems.append(f"âŒ KullanÄ±cÄ± film kapsamÄ± dÃ¼ÅŸÃ¼k ({avg_coverage:.1f}%)")
    else:
        print(f"   âœ… KullanÄ±cÄ± film kapsamÄ± yeterli ({avg_coverage:.1f}%)")
    
    # Problem 3: Content-based sÄ±nÄ±rlamasÄ±
    if similarities and np.mean(similarities) < 0.15:
        problems.append("âŒ Content-based benzerlik Ã§ok dÃ¼ÅŸÃ¼k (filmler iÃ§erik olarak farklÄ±)")
    
    if problems:
        print("\n   ğŸš¨ TESPÄ°T EDÄ°LEN PROBLEMLER:")
        for p in problems:
            print(f"      {p}")
    
    # 6. Ã–neriler
    print("\nğŸ’¡ 6. Ä°YÄ°LEÅTÄ°RME Ã–NERÄ°LERÄ°")
    print("-" * 50)
    
    print("""
   1. DAHA GENIÅ TOP-N KULLANIN:
      â€¢ top_n=10 yerine top_n=20 veya 30 deneyin
      â€¢ Content-based sistemler iÃ§in %20-30 hit rate normaldir
   
   2. RESTRICT_TO_LINKS'Ä° KAPATIN:
      â€¢ MovieLens filtresi aktifse, Ã¶neri havuzu daralÄ±r
      â€¢ Bu filtreyi kapatmak hit rate'i artÄ±rabilir
   
   3. METHOD DEÄÄ°ÅTÄ°RÄ°N:
      â€¢ "score_avg" yerine "vector_avg" deneyin
      â€¢ Veya "profile" modunu kullanÄ±n
   
   4. RATING THRESHOLD'U DÃœÅÃœRÃœn:
      â€¢ 4.0 yerine 3.5 deneyin
      â€¢ Daha fazla film = daha iyi profil
   
   5. BU NORMALDÄ°R:
      â€¢ Content-based sistemler collaborative filtering kadar
        yÃ¼ksek hit rate vermez
      â€¢ %15-30 arasÄ± hit rate content-based iÃ§in kabul edilebilir
      â€¢ Ã‡Ã¼nkÃ¼ kullanÄ±cÄ±lar her zaman "benzer iÃ§erikli" filmler sevmez
    """)
    
    print("=" * 70)


if __name__ == "__main__":
    diagnose()


Şimdi olayı “bu yöntem diğerlerinden nasıl farklı?” diye toparlayalım.

Senin sorduğun:
**UserId kullanan İşbirlikçi Filtreleme (user-based Collaborative Filtering)**

Bunu 3 şeyle karşılaştıralım:

---

## 1) Association Rules (ARL) vs User-based CF

**Association Rules (senin ARL modülün)**

* Input: “Hangi filmler birlikte beğenilmiş?”
* UserId’e TAKILMIYOR, sadece **birlikte geçen film setlerine** bakıyor.
* Film A’yı sevenlerin %X’i Film B’yi de seviyorsa:

  * “A → B” kuralı, support / confidence / lift ile ölçülüyor.
* Model **herkese aynı kural kümesini** kullanıyor.

  * Sen kullanıcıdan “şu filmleri sevdim” listesi alıyorsun,
  * Bu filmlerle eşleşen kurallardan consequents’leri öneriyorsun.
* Rating değeri genelde **0/1’e indirgenmiş** (beğendi / beğenmedi). Kaç puan verdiği çok önemli değil, eşiğin üstündeyse “beğendi”.

**User-based Collaborative Filtering**

* Input: `(userId, movieId, rating)` matrisi.
* **UserId çok kritik**: “Benim rating pattern’ime benzeyen kullanıcılar hangileri?” diye bakıyor.
* Her kullanıcı **bir vektör**:

  * Kullanıcı u: [American Psycho=5, Fight Club=4, …]
* Sana benzeyen kullanıcıları buluyor (cosine / Pearson).
* Senin izlemediğin film için:

  * “Benzer kullanıcılar bu filme kaç puan verdi?”
  * Bu puanlardan **tahmini rating** hesaplıyor.
* **Kişiye özel**: Aynı film, iki farklı kullanıcıya çok farklı skorlarla önerilebilir.

Özet cümle (rapora yazmalık):

> ARL, filmler arasındaki global birliktelik ilişkilerine bakar (A’yı seven B’yi de sever).
> User-based CF ise benzer kullanıcıların rating paternlerine bakarak **kullanıcı bazlı puan tahmini** yapar.

---

## 2) User-based CF vs Item-based CF

İkisi de collaborative filtering ailesi ama bakış açıları farklı:

* **User-based CF**

  * “Benim gibi kullanıcılar kim?” (user-user benzerlik)
  * Onların beğendiği filmler üzerinden öneri.

* **Item-based CF**

  * “Bu filme benzeyen filmler hangileri?” (movie-movie benzerlik)
  * Kullanıcının yüksek puan verdiği filmler için:

    * Bu filmlere benzer diğer filmler önerilir.

Kısaca:

> User-based: Kullanıcılar arası benzerlik.
> Item-based: Filmler arası benzerlik.

---

## 3) User-based CF vs Content-based Filtering

* **Content-based (içerik tabanlı)**

  * Film özelliklerini kullanır: tür, yönetmen, oyuncu, açıklama, vs.
  * Kullanıcının sevdiği filmlerin “içerik profilini” çıkarır.
  * Aynı türe / yönetmene / benzer feature’lara sahip yeni filmler önerir.
  * Diğer kullanıcıları hiç bilmeden de çalışabilir (sadece senin geçmişin yeter).

* **User-based CF**

  * İçeriğe bakmaz; sadece **rating matrisine** bakar.
  * Senin “benzer zevkli” insanları bulur,
  * Onların sevdiğini sana taşır.

---

## Tek cümlelik fark özetleri

Böyle ezberleyebilirsin:

* **ARL vs CF:**
  “ARL → film–film birliktelik analizi,
  CF → kullanıcı davranışından rating tahmini.”

* **User-based vs Item-based:**
  “User-based → benzer kullanıcı bul,
  Item-based → benzer film bul.”

* **CF vs Content-based:**
  “CF → diğer kullanıcıların davranışına dayanır,
  Content-based → filmlerin özelliklerine dayanır.”

İstersen bu farkları doğrudan rapora koyabileceğin, 1 paragraf + küçük tablo halinde de yazabilirim.

Şöyle yapalım: Bu projeyi 3 ayrı öneri algoritması olarak düşüneceğiz ve hepsi aynı veri setinden beslenecek:

1. Association Rules (ARL) – zaten büyük kısmını yazdın
2. Item-based Collaborative Filtering
3. Content-based (genre + overview metni)

Her biri için: hangi dosyaları kullanacağız, nasıl feature üreteceğiz, hangi kütüphaneler, hangi fonksiyonlar, Streamlit’te nasıl bağlayacaksın – hepsini adım adım yazıyorum.

---

## 1) Association Rules (ARL) – Mevcut modülün

Amaç:
Aynı kullanıcıların birlikte sevdiği filmlerden “X’i seven Y’yi de sever” kuralları çıkarmak.

Kullanılacak dosyalar:

* `ratings_small.csv` → userId, movieId, rating
* `links_small.csv` → movieId, tmdbId
* `movies_metadata.csv` → id (tmdb id), title, genres

Kullanılacak kütüphaneler:

* `pandas`, `numpy`
* `mlxtend.frequent_patterns` (apriori, association_rules)
* Streamlit tarafında: `streamlit`, `plotly`, `networkx` (görselleştirme için)
* Sen zaten bunları kullanıyorsun.

Pipeline (backend – `recommender_arl.py`):

1. Ham veriyi yükle

   * `load_raw_data()` fonksiyonu bunu yapıyor.
   * Sadece gerekli kolonları alıyorsun.

2. `movieId -> title` mapping oluştur

   * `build_movie_mapping()` ile:

     * `links_small` içindeki `tmdbId` ile `movies_metadata` içindeki `id`’yi eşliyorsun.
     * Böylece `movieId` → `title` tablosu oluşuyor.
   * Bunu `movie_mapping.pkl` olarak kaydediyorsun.

3. Beğenilen filmleri filtrele

   * `filter_liked_ratings(ratings, min_rating=4.0)`
   * rating ≥ 4 olanları “beğenildi” kabul ediyorsun.
   * Çok az beğenilen filmleri elemek için `filter_infrequent_movies(min_likes=10)` kullanıyorsun.

4. User–movie 0/1 matrisi kur

   * `build_user_movie_matrix()`
   * Index: userId, Columns: movieId
   * Hücre: kullanıcı o filmi beğenmişse 1, yoksa 0 (bool).

5. Apriori + association rules

   * `generate_association_rules(basket_df, min_support, min_confidence, min_lift, max_len=2)`
   * `apriori()` ile sık itemset’ler,
   * `association_rules()` ile kurallar.
   * Filtre: support ≥ x, confidence ≥ y, lift ≥ z
   * Ek olarak `score = confidence * lift` hesaplıyorsun ve sıralamada kullanıyorsun.

6. Artefaktları kaydet

   * `movie_mapping.pkl`
   * `association_rules.pkl`
   * `artifacts_meta.json` (kullanılan parametreler)

7. Prediction fonksiyonu

   * `recommend_with_association_rules(liked_titles, top_n, mapping_path, rules_path)`
   * Adımlar:

     * Girilen film adlarını `movieId`’ye çevir (`_titles_to_movie_ids`)
     * `antecedents` ⊆ seçilen filmler olan kuralları filtrele
     * `consequents`’teki filmleri öneri listesine ekle
     * Aynı filme gelen birden çok kural varsa metrikleri `max` ile birleştir
     * `score`’a göre sırala, ilk `top_n`’i dön.

Streamlit tarafı (şu anki app’in):

* Sayfa açılışında:

  * `load_raw_frames()` ile veri
  * `load_artifacts()` ile mapping + rules + metadata
* Eşikler artık eğitimde sabit, app’te sadece:

  * `FILTER_MIN_SUPPORT`, `FILTER_MIN_CONFIDENCE`, `FILTER_MIN_LIFT` ile kuralları filtreliyorsun.
* Kullanıcı:

  * Sol taraftan film seçiyor,
  * `recommend_from_rules()` çağrılıyor,
  * Kartlar ve tablo ile öneriler gösteriliyor,
  * Ek olarak:

    * Kuralların histogramları (support/confidence/lift dağılımı),
    * 3D scatter, network graph,
    * Tür analizi,
    * CSV / rapor export.

Bu yöntem senin “pazar yerinden alışveriş yapan kullanıcılar” mantığıyla çalışan, association rules tabanlı modülün. Şu an gayet iyi durumda; bundan sonra dokunuşlar daha çok görsel/yorum seviyesinde olur.

---

## 2) Item-based Collaborative Filtering (Benzer film tavsiyesi – rating bazlı)

Amaç:
“Bu filmi beğenenler şunları da beğendi” mantığını, kural çıkarma yerine, doğrudan rating benzerliğine göre yapmak.

Kullanılacak dosyalar:

* `ratings_small.csv` (ana veri)
* `movie_mapping.pkl` (ARL’den gelen mapping’i tekrar kullanırız)
* İstersen popularity/tür için `movies_metadata.csv` de eklenebilir ama şart değil.

Kullanılacak kütüphaneler:

* `pandas`, `numpy`
* `sklearn.metrics.pairwise` → `cosine_similarity`
* İstersen `scipy.sparse` (performans için)
* Streamlit tarafında yine aynı.

Adım adım plan:

1. User–movie rating matrisi oluştur

   * ratings_small’tan pivot:

     ```python
     ratings = pd.read_csv(...)
     rating_matrix = ratings.pivot_table(
         index="userId",
         columns="movieId",
         values="rating"
     )
     ```
   * Eksik rating’ler NaN – bunları:

     * ya 0 ile doldurursun (basit),
     * ya ortalama ile doldurursun,
     * ya sparse matrix olarak tutarsın.

2. Film–film benzerlik matrisi hesapla

   * Amaç: her film için diğer filmlerle cosine similarity.
   * Örnek:

     ```python
     from sklearn.metrics.pairwise import cosine_similarity

     # movieId sütunlarını sıralı hale getir
     movie_ids = rating_matrix.columns
     movie_features = np.nan_to_num(rating_matrix.values)  # NaN -> 0

     sim_matrix = cosine_similarity(movie_features.T)  # film x film
     sim_df = pd.DataFrame(sim_matrix, index=movie_ids, columns=movie_ids)
     ```
   * Bu matrisi bir kere hesaplayıp `.pkl` olarak kaydedebilirsin:

     * `models/item_sim_matrix.pkl`

3. Bir film için “benzer filmler” fonksiyonu yaz

   * Input: `movie_title`, `top_n`
   * Adımlar:

     1. `movie_title` → `movieId` (mapping’den)
     2. `sim_df.loc[movie_id]` satırını çek
     3. Kendini hariç tut, en yüksek similarity’e sahip `top_n` filmi seç
     4. movieId → title + opsiyonel: ortalama rating, izlenme sayısı gibi bilgiler ekle.
   * Örnek:

     ```python
     def recommend_item_based(movie_title, top_n=10):
         movie_id = title_to_id[movie_title]
         sims = sim_df.loc[movie_id].drop(movie_id)
         top = sims.sort_values(ascending=False).head(top_n)
         recs = pd.DataFrame({
             "movieId": top.index,
             "similarity": top.values
         }).merge(mapping_df, on="movieId", how="left")
         return recs
     ```

4. Kullanıcı birden fazla film seçerse ne olacak?

   * Basit yöntem: seçilen filmlerin similarity vektörlerini ortalama al:

     ```python
     def recommend_from_multiple(liked_ids, top_n=10):
         sims = sim_df[liked_ids].mean(axis=1)   # her film için ortalama benzerlik
         sims = sims.drop(liked_ids)             # izlenmişleri çıkar
         top = sims.sort_values(ascending=False).head(top_n)
         ...
     ```
   * Böylece collaborative filtering de “seçilen film setine göre” öneri üretecek.

5. Streamlit entegrasyonu

   * Uygulamada bir yerden algoritma seçtirebilirsin:

     * Radyo düğmesi: `Algoritma: [Association Rules, Item-based CF, Content-based]`
   * Eğer “Item-based CF” seçilirse:

     * Aynı film seçme arayüzü kullanılabilir.
     * `recommend_item_based` fonksiyonu çağrılır.
     * Kart tasarımı aynı kalır ama alt açıklamada:

       * “Benzerlik (cosine similarity)” metriğini gösterirsin.
   * Ek görseller:

     * Seçtiğin film ile en benzer 10 filmin bar grafiği (similarity skoru).
     * user–movie rating heatmap vs. istersen.

Bu yöntemle association rules’tan bağımsız, sadece rating benzerliğine dayalı bir önerici elde etmiş oluyorsun. Aynı kullanıcılar üzerinden çalıştığı için sonuçlar bir miktar benzer olabilir ama ARL’den farklı kombinasyonlar da yakalar.

---

## 3) Content-based Recommender (Tür ve metin bazlı)

Amaç:
Kullanıcının sevdiği filmlerin “içeriğine” bakıp (genre, overview, keywords vb.) ona benzer içerikte filmler bulmak. Rating hiç olmasa bile çalışabilir.

Kullanılacak dosyalar:

* `movies_metadata.csv` (ana kaynak)

  * `id`, `title`, `genres`, `overview`, `vote_average`, `vote_count`...
* Opsiyonel: `links_small.csv` ile sadece rating’lerde görülen filmlerle kesiştirebilirsin (daha küçük uzay).

Kullanılacak kütüphaneler:

* `pandas`, `numpy`
* `ast` (genre alanı JSON string, parse için)
* `sklearn.feature_extraction.text` → `TfidfVectorizer`
* `sklearn.metrics.pairwise` → `cosine_similarity`

Adım adım plan:

1. Film içerik tablosu hazırla

   * `movies_metadata.csv`’da şu kolonları al:

     * `id` (tmdb id), `title`, `genres`, `overview`
   * `genres` alanını listeye çevir:

     ```python
     import ast

     def parse_genres(x):
         try:
             items = ast.literal_eval(x)
             return [d["name"] for d in items if isinstance(d, dict)]
         except Exception:
             return []
     metadata["genres_list"] = metadata["genres"].apply(parse_genres)
     ```
   * Tek bir “content_string” oluştur:

     * Genre isimleri + overview metnini birleştir:

       ```python
       metadata["content"] = metadata["genres_list"].apply(lambda xs: " ".join(xs)) + " " + metadata["overview"].fillna("")
       ```

2. TF-IDF ile vektörleştir

   * İngilizce stopword’leri çıkararak:

     ```python
     from sklearn.feature_extraction.text import TfidfVectorizer

     tfidf = TfidfVectorizer(
         stop_words="english",
         max_features=20000  # istersen sınır koy
     )
     tfidf_matrix = tfidf.fit_transform(metadata["content"].fillna(""))
     ```
   * Sonuç: film sayısı × kelime sayısı boyutlu sparse matris.

3. Film–film benzerlik matrisi

   * Cosine similarity:

     ```python
     from sklearn.metrics.pairwise import cosine_similarity

     sim_content = cosine_similarity(tfidf_matrix, tfidf_matrix)
     ```
   * Ve bunu DataFrame’e:

     ```python
     sim_content_df = pd.DataFrame(
         sim_content,
         index=metadata["id"].astype(int),
         columns=metadata["id"].astype(int)
     )
     ```
   * Not: Buradaki id tmdb id; istersen `links_small` ile `movieId`’ye çevirip önceki mapping ile aynı id alanına çekebilirsin.

4. Öneri fonksiyonu

   * Input: `movie_title`, `top_n`
   * Adımlar:

     1. `title` → `id` (metadata’dan)
     2. `sim_content_df.loc[id]` satırını çek
     3. En benzer `top_n` filmi seç (kendini çıkar)
     4. title, genres, overview özetini dön.
   * Python:

     ```python
     def recommend_content_based(title, top_n=10):
         row = metadata[metadata["title"] == title]
         if row.empty:
             return pd.DataFrame()
         mid = int(row["id"].iloc[0])
         sims = sim_content_df.loc[mid].drop(mid)
         top = sims.sort_values(ascending=False).head(top_n)
         recs = (
             metadata.set_index("id")
             .loc[top.index, ["title", "genres_list", "overview"]]
             .reset_index(drop=True)
         )
         recs["similarity"] = top.values
         return recs
     ```

5. Birden fazla film seçimi

   * Aynı item-based CF’deki gibi:

     * Seçilen filmlerin benzerlik vektörlerini ortalama al:

       ```python
       def recommend_content_based_multi(titles, top_n=10):
           ids = [...]
           sims = sim_content_df[ids].mean(axis=1)
           sims = sims.drop(ids, errors="ignore")
           top = sims.sort_values(ascending=False).head(top_n)
           ...
       ```

6. Streamlit entegrasyonu

   * Algoritma seçimi:

     * Radyo: `algorithm = st.radio("Öneri algoritması", ["Association Rules", "Item-based CF", "Content-based"])`
   * Eğer `Content-based` seçilirse:

     * Sol tarafta film seçimi yine title üzerinden olacak ama bu sefer:

       * Eğer seçilen film rating verisinde yoksa bile sadece metadata’dan gelip öneri üretebilecek.
     * Kartlarda gösterebileceğin ek bilgiler:

       * Genre listesi,
       * Overview’den kısa bir özet (`overview[:150] + "..."`),
       * similarity skoru.

7. Performans konusu

   * TF-IDF + cosine similarity biraz maliyetli ama film sayısı bu dataset’te çok büyük değil; yine de:

     * TF-IDF’i bir kere hesaplayıp `.npz` / `.pkl` olarak kaydet,
     * similarity matrisini istersen numpy array olarak kaydet.
   * Streamlit’te:

     * `@st.cache_data` ile sim matrisini load ettiğinde tekrar hesaplama yapmaz.

---

## Önerilen çalışma sırası

1. ARL modülünü “stabil” hale getirdin; artık sadece küçük iyileştirmeler.
2. Sonra:

   * `src/recommender_itemcf.py` diye yeni bir dosya aç:

     * user–movie matrisi
     * item similarity matrisi
     * `recommend_item_based`, `recommend_item_based_multi` fonksiyonları
     * artefakt kaydetme (benzerlik matrisini diske yaz).
3. Ardından:

   * `src/recommender_content.py`

     * metadata yükleme
     * TF-IDF + similarity
     * `recommend_content_based` fonksiyonları.
4. En son:

   * Streamlit app’te algoritma seçimi ve uygun backend fonksiyonunu çağırma.
   * Her algoritma için kartlarda farklı metrik göster (ARL: support/confidence/lift; CF: similarity; Content-based: similarity + genre).

Böylece projende:

* 1 tane kural tabanlı (association rules),
* 1 tane rating bazlı collaborative filtering,
* 1 tane içerik tabanlı (content-based)

olmak üzere 3 farklı öneri algoritması olacak; raporda ve sunumda her birinin avantaj/dezavantajını, hangi senaryoda daha iyi çalıştığını karşılaştırabilirsin.

Hazırsan bir sonraki adımda istersen önce Item-based CF için iskelet kodu birlikte çıkarabiliriz; sen direkt doldurup çalıştırırsın.





örnek plan :

---

## 1) Şu ana kadar yaptıklarımız (Mevcut Durum)

### 1.1 Veri kaynakları

Projede Kaggle’daki **The Movies Dataset** içinden şu üç dosya kullanılıyor:

* `data/raw/ratings_small.csv`

  * Kolonlar: `userId`, `movieId`, `rating`, `timestamp`
* `data/raw/links_small.csv`

  * Kolonlar: `movieId`, `imdbId`, `tmdbId`
* `data/raw/movies_metadata.csv`

  * Özellikle kullanılan kolonlar: `id` (tmdb id), `title`, `genres`, `overview`, vs.

---

### 1.2 Association Rules backend’i (`src/recommender_arl.py`)

Bu modül **association rules tabanlı film öneri motorunu** uçtan uca kuruyor:

1. **Ham veriyi yükleme**

   * `load_raw_data()` fonksiyonu:

     * `ratings_small.csv`, `links_small.csv`, `movies_metadata.csv` dosyalarını okuyor.
     * `ratings` için tipleri net (`userId`/`movieId` int, `rating` float).

2. **movieId → title mapping’i**

   * `build_movie_mapping(links_df, metadata_df)`:

     * `links_small.tmdbId` ile `movies_metadata.id` eşleştiriliyor.
     * Sonuç: `movieId` ve `title` içeren, tekrarları temizlenmiş bir DataFrame.
   * `save_movie_mapping()` ile `models/movie_mapping.pkl` olarak kaydediliyor.
   * `load_movie_mapping()` ile tekrar okunabiliyor.

3. **Beğenilen filmleri filtreleme**

   * `filter_liked_ratings(ratings, min_rating=4.0)`:

     * `rating >= 4.0` olan satırlar “beğenildi” kabul ediliyor.
   * `filter_infrequent_movies(liked_ratings, min_likes=10)`:

     * 10’dan az beğeni alan filmler atılıyor (Apriori’yi hızlandırmak için).

4. **User–movie 0/1 matrisi**

   * `build_user_movie_matrix(liked_ratings)`:

     * Satırlar: `userId`, sütunlar: `movieId`
     * Hücre: kullanıcı o filmi beğendiyse `True`, aksi halde `False`.
     * Bu matris Apriori için input olarak kullanılıyor.

5. **Apriori + association rules**

   * `generate_association_rules(basket_df, min_support, min_confidence, min_lift, max_len=2)`:

     * `mlxtend.frequent_patterns.apriori` ile sık itemset’ler üretiliyor.
     * `association_rules(..., metric="lift", min_threshold=min_lift)` ile kurallar çıkıyor.
     * Filtreleme:

       * `support >= min_support`
       * `confidence >= min_confidence`
       * `lift >= min_lift`
     * `antecedents` / `consequents` integer set’lere dönüştürülüyor.
     * `score = confidence * lift` hesaplanıyor ve sıralamada kullanılıyor.
   * Kurallar `models/association_rules.pkl` olarak kaydediliyor.

6. **Artefakt metadata’sı**

   * `save_artifact_metadata()` ile `models/artifacts_meta.json` dosyasında şu parametreler tutuluyor:

     * `min_rating_for_like`
     * `min_support`
     * `min_confidence`
     * `min_lift`
     * `min_movie_likes`
     * `max_len`

7. **Öneri fonksiyonu**

   * `recommend_with_association_rules(liked_titles, top_n, mapping_path, rules_path)`:

     * Girilen film adları `_titles_to_movie_ids()` ile `movieId` listesine dönüyor.
     * `antecedents` kümesi tamamen kullanıcının sevdiği filmlerin alt kümesi olan kurallar filtreleniyor.
     * `consequents` tarafındaki filmler öneri adayı olarak toplanıyor.
     * Aynı filme gelen birden fazla kural varsa `support/confidence/lift/score` için `max` alınıyor.
     * Sonuç DataFrame:

       * Kolonlar: `title`, `movieId`, `score`, `confidence`, `lift`, `support`
       * `score`’a göre sıralı, ilk `top_n` kayıt döndürülüyor.

8. **CLI çalıştırma**

   * `python src/recommender_arl.py` komutu:

     * Tüm pipeline’ı çalıştırıp:

       * `movie_mapping.pkl`
       * `association_rules.pkl`
       * `artifacts_meta.json`
     * dosyalarını oluşturuyor.
     * Örnek olarak `["Inception", "Interstellar", "The Dark Knight"]` için öneri üretiyor.

---

### 1.3 Streamlit arayüzü (`app/movie_recommender_app.py`)

Bu dosya “**Movie Recommender Pro**” isimli Streamlit uygulamasını sağlıyor:

1. **Genel yapı**

   * `ROOT_DIR` üzerinden `src` import ediliyor: `import src.recommender_arl as arl`.
   * Sayfa config: başlık, ikon, geniş layout.
   * Custom CSS ile kartlar, tab’ler ve metric görünümleri tasarlanmış.

2. **Cache’lenen yardımcı fonksiyonlar**

   * `load_raw_frames()` → `arl.load_raw_data()` çağırıyor.
   * `load_artifacts()` → mapping, rules, metadata yüklüyor.
   * `compute_overview_stats()`, `top_movies_by_count()`, `user_activity_histogram()`,
     `genre_popularity()`, `compute_genre_analysis()`, `compute_advanced_metrics()`:

     * Veri setiyle ilgili genel istatistikler, tür dağılımı, genre co-occurrence vs. hesaplanıyor.
   * `rules_with_titles()` → `antecedents` ve `consequents` set’lerini film adlarına çeviriyor.
   * `network_graph()`, `create_3d_scatter()`, `create_heatmap_top_movies()`:

     * Kuralları ve filmleri görselleştiren grafikler üretiyor.

3. **Sabit kural eşikleri (UI tarafı)**

   * Streamlit içinde filtreler sabitlenmiş:

     * `FILTER_MIN_SUPPORT = 0.01`
     * `FILTER_MIN_CONFIDENCE = 0.30`
     * `FILTER_MIN_LIFT = 1.0`
   * Uygulama **Apriori’yi tekrar çalıştırmıyor**, sadece bu eşiklere göre daha önce kaydedilmiş kuralları süzüyor.

4. **Kullanıcı film seçimi ve öneri**

   * Sol sidebar:

     * `top_n` slider → kaç öneri döneceği.
     * `multiselect` ile sevilen filmler seçiliyor (`mapping_df["title"]` listesinden).
   * `recommend_from_rules(liked_titles, mapping_df, rules_df, top_n)` fonksiyonu:

     * ARL backend’deki `_titles_to_movie_ids` fonksiyonunu kullanıyor.
     * Seçilen filmler antecedent olan kurallara göre öneri üretiyor.
   * Sonuçlar:

     * “Seçtiğiniz Filmler” bölümü (gradient kartlar).
     * “Size Özel Film Önerileri” (her film için skor, confidence, lift).
     * Alt tarafta detaylı tablo + metrik grafikleri.

5. **İleri analiz ve dışa aktarım**

   * Conviction, leverage, max lift, güçlü kural sayısı gibi advanced metrikler hesaplanıp gösteriliyor.
   * En çok antecedent / consequent olan filmler listeleniyor.
   * Çoklu film kombinasyonu (antecedents uzunluğu ≥ 2) için kural bazlı analiz yapılıyor.
   * CSV ve text rapor indirme butonları:

     * Tüm kuralları CSV
     * Özet rapor (txt)
     * Önerileri CSV

---

## 2) Bundan Sonra Yapılacaklar (Plan + Fikirler)

Genel hedef:
ARL modülünün yanına **iki ek öneri algoritması** eklemek:

1. Item-based Collaborative Filtering (rating tabanlı benzerlik)
2. Content-based Recommendation (genre + overview metni tabanlı)

Ve Streamlit arayüzünde kullanıcıya, aynı film seçimi arayüzünü kullanarak **üç farklı algoritma arasında seçim yapma** imkânı vermek.

---

### 2.1 Item-based Collaborative Filtering

**Amaç:**
Aynı filmleri benzer şekilde oylayan kullanıcılar üzerinden, “Bu filmi beğenenler şunları da beğendi” mantığını rating benzerliği ile kurmak.

**Yeni backend dosyası:** `src/recommender_itemcf.py`

**Yapılacaklar:**

1. **User–movie rating matrisi oluştur**

   * `ratings_small.csv` kullan:

     ```python
     ratings = pd.read_csv(...)
     rating_matrix = ratings.pivot_table(
         index="userId",
         columns="movieId",
         values="rating"
     )
     ```
   * Eksik rating’leri `0` ile doldurma (ilk basit versiyon için yeterli):

     ```python
     rating_matrix_filled = rating_matrix.fillna(0.0)
     ```

2. **Film–film benzerlik matrisi (cosine similarity)**

   * `sklearn.metrics.pairwise.cosine_similarity` kullan:

     ```python
     from sklearn.metrics.pairwise import cosine_similarity

     movie_ids = rating_matrix_filled.columns
     sim_matrix = cosine_similarity(rating_matrix_filled.T)  # film x film
     sim_df = pd.DataFrame(sim_matrix, index=movie_ids, columns=movie_ids)
     ```
   * Bu DataFrame’i `models/item_similarity.pkl` olarak kaydet:

     ```python
     sim_df.to_pickle(MODELS_DIR / "item_similarity.pkl")
     ```

3. **Tek film için benzer film fonksiyonu**

   * `movie_title` → `movieId` (mevcut `movie_mapping.pkl`’i kullan).
   * Belirli bir `movieId` için:

     ```python
     sims = sim_df.loc[movie_id].drop(movie_id)
     top = sims.sort_values(ascending=False).head(top_n)
     ```
   * Sonuç DataFrame:

     * `movieId`, `similarity`, `title`, istersen `mean_rating`, `rating_count`.

4. **Birden fazla film seçimi**

   * Kullanıcı birden çok film seçerse:

     * O filmlerin similarity sütunlarının ortalamasını al:

       ```python
       sims = sim_df[liked_ids].mean(axis=1)
       sims = sims.drop(liked_ids, errors="ignore")
       top = sims.sort_values(ascending=False).head(top_n)
       ```
   * Böylece ortak zevke göre benzer filmler bulunacak.

5. **API benzeri arayüz**

   * Bu dosyada aşağıdaki gibi fonksiyonlar olsun (agent bunları yazabilir/iyileştirebilir):

     * `build_and_save_item_similarity(...)`
     * `load_item_similarity(...)`
     * `recommend_item_based(liked_titles: list[str], top_n: int) -> pd.DataFrame`
   * ARL’de olduğu gibi, `recommend_item_based` doğrudan Streamlit tarafından kullanılacak.

6. **Streamlit entegrasyonu**

   * `movie_recommender_app.py` içinde:

     * Bir radyo ekle:

       ```python
       algo = st.radio(
           "Öneri algoritması",
           ["Association Rules", "Item-based CF", "Content-based"],
           index=0
       )
       ```
     * Eğer `algo == "Item-based CF"` ise:

       * `recs = recommend_item_based(liked_titles, top_n=top_n)` çağır.
       * Kartlarda:

         * `similarity` değerini göster (0–1 arası).
         * İstersen progress bar’ı similarity’ye göre doldur.

---

### 2.2 Content-based Recommendation (genre + overview metni)

**Amaç:**
Filmlerin **içerik bilgisine** (genre listesi + overview metni) bakarak benzer filmleri önermek. Rating olmasa bile çalışabilmeli.

**Yeni backend dosyası:** `src/recommender_content.py`

**Yapılacaklar:**

1. **Metadata’dan içerik alanlarını hazırlama**

   * `movies_metadata.csv` içinden:

     * `id` (tmdb id), `title`, `genres`, `overview` kolonlarını al.
   * `genres` kolonunu parse et (şu an Streamlit’te kullandığımız `_parse_genres` fonksiyonunu burada da kullanabiliriz):

     ```python
     import ast

     def parse_genres(value: str) -> list[str]:
         ...
     metadata["genres_list"] = metadata["genres"].apply(parse_genres)
     ```
   * Tek bir metin alanı üret:

     ```python
     metadata["content"] = (
         metadata["genres_list"].apply(lambda xs: " ".join(xs)) + " " +
         metadata["overview"].fillna("")
     )
     ```

2. **TF-IDF vektörleştirme**

   * `sklearn.feature_extraction.text.TfidfVectorizer` ile:

     ```python
     from sklearn.feature_extraction.text import TfidfVectorizer

     tfidf = TfidfVectorizer(
         stop_words="english",
         max_features=20000
     )
     tfidf_matrix = tfidf.fit_transform(metadata["content"].fillna(""))
     ```
   * TF-IDF + similarity matrisini dosyaya kaydedebilirsin (agent yönetebilir):

     * Örn: `models/tfidf_content.npz`, `models/content_similarity.pkl`.

3. **Film–film içerik benzerliği**

   * Cosine similarity:

     ```python
     from sklearn.metrics.pairwise import cosine_similarity
     sim_content = cosine_similarity(tfidf_matrix, tfidf_matrix)
     ```
   * DataFrame:

     ```python
     ids = metadata["id"].astype(int)
     sim_content_df = pd.DataFrame(sim_content, index=ids, columns=ids)
     ```

4. **Title → id mapping**

   * `metadata` içinde:

     ```python
     title_to_id = (
         metadata.dropna(subset=["title"])
         .drop_duplicates(subset=["title"])
         .set_index("title")["id"]
     )
     ```

5. **Öneri fonksiyonu**

   * `recommend_content_based(liked_titles: list[str], top_n: int) -> pd.DataFrame`
   * Eğer tek film:

     * `title` → `id`
     * `sim_content_df.loc[id]`’i al, kendi id’yi at, en yüksek benzerlikleri seç.
   * Eğer çoklu film:

     * `ids` listesi üzerinden:

       ```python
       sims = sim_content_df[ids].mean(axis=1)
       sims = sims.drop(ids, errors="ignore")
       top = sims.sort_values(ascending=False).head(top_n)
       ```
   * Sonuç DataFrame:

     * `title`, `similarity`, `genres_list`, `overview` (kısaltılmış), `id`.

6. **Streamlit entegrasyonu**

   * `algo == "Content-based"` durumunda:

     * `recs = recommend_content_based(liked_titles, top_n=top_n)` çağır.
     * Kartlarda:

       * `similarity` (0–1)
       * Genre listesi (`Aksiyon, Dram, ...`)
       * Overview’den snippet (`overview[:160] + "..."`).

---

### 2.3 Genel ilkeler (agent için kısa not)

* Mevcut `src/recommender_arl.py` ve `app/movie_recommender_app.py` yapısını **bozmadan**, yanına yeni modüller ekle.
* Her yeni modülde:

  * Fonksiyonlara type hint yaz (`-> pd.DataFrame`, `-> tuple[...]` vs.).
  * Gerekli yerlerde dokümantasyon (docstring) eklensin.
* Artefaktları `models/` klasöründe tut:

  * `item_similarity.pkl`
  * `content_similarity.pkl`
  * Gerekirse TF-IDF için ayrı dosya.
* Streamlit tarafında:

  * Aynı "film seçimi" arayüzü tüm algoritmalar için ortak olsun.
  * Sadece altta hesaplama ve gösterilen metrikler değişsin.
* Performans önemli ama dataset küçük; önce **temiz ve okunabilir** bir çözüm, sonra gerekiyorsa optimizasyon.

---